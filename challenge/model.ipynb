{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Feature Importante and with Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('../data/data.csv')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def get_period_day(date):\n",
    "    date_time = datetime.strptime(date, '%Y-%m-%d %H:%M:%S').time()\n",
    "    morning_min = datetime.strptime(\"05:00\", '%H:%M').time()\n",
    "    morning_max = datetime.strptime(\"11:59\", '%H:%M').time()\n",
    "    afternoon_min = datetime.strptime(\"12:00\", '%H:%M').time()\n",
    "    afternoon_max = datetime.strptime(\"18:59\", '%H:%M').time()\n",
    "    evening_min = datetime.strptime(\"19:00\", '%H:%M').time()\n",
    "    evening_max = datetime.strptime(\"23:59\", '%H:%M').time()\n",
    "    night_min = datetime.strptime(\"00:00\", '%H:%M').time()\n",
    "    night_max = datetime.strptime(\"4:59\", '%H:%M').time()\n",
    "    \n",
    "    if(date_time > morning_min and date_time < morning_max):\n",
    "        return 'mañana'\n",
    "    elif(date_time > afternoon_min and date_time < afternoon_max):\n",
    "        return 'tarde'\n",
    "    elif(\n",
    "        (date_time > evening_min and date_time < evening_max) or\n",
    "        (date_time > night_min and date_time < night_max)\n",
    "    ):\n",
    "        return 'noche'\n",
    "    \n",
    "def is_high_season(fecha):\n",
    "    fecha_año = int(fecha.split('-')[0])\n",
    "    fecha = datetime.strptime(fecha, '%Y-%m-%d %H:%M:%S')\n",
    "    range1_min = datetime.strptime('15-Dec', '%d-%b').replace(year = fecha_año)\n",
    "    range1_max = datetime.strptime('31-Dec', '%d-%b').replace(year = fecha_año)\n",
    "    range2_min = datetime.strptime('1-Jan', '%d-%b').replace(year = fecha_año)\n",
    "    range2_max = datetime.strptime('3-Mar', '%d-%b').replace(year = fecha_año)\n",
    "    range3_min = datetime.strptime('15-Jul', '%d-%b').replace(year = fecha_año)\n",
    "    range3_max = datetime.strptime('31-Jul', '%d-%b').replace(year = fecha_año)\n",
    "    range4_min = datetime.strptime('11-Sep', '%d-%b').replace(year = fecha_año)\n",
    "    range4_max = datetime.strptime('30-Sep', '%d-%b').replace(year = fecha_año)\n",
    "    \n",
    "    if ((fecha >= range1_min and fecha <= range1_max) or \n",
    "        (fecha >= range2_min and fecha <= range2_max) or \n",
    "        (fecha >= range3_min and fecha <= range3_max) or\n",
    "        (fecha >= range4_min and fecha <= range4_max)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_min_diff(data):\n",
    "    fecha_o = datetime.strptime(data['Fecha-O'], '%Y-%m-%d %H:%M:%S')\n",
    "    fecha_i = datetime.strptime(data['Fecha-I'], '%Y-%m-%d %H:%M:%S')\n",
    "    min_diff = ((fecha_o - fecha_i).total_seconds())/60\n",
    "    return min_diff\n",
    "\n",
    "data['period_day'] = data['Fecha-I'].apply(get_period_day)\n",
    "data['high_season'] = data['Fecha-I'].apply(is_high_season)\n",
    "data['min_diff'] = data.apply(get_min_diff, axis = 1)\n",
    "\n",
    "threshold_in_minutes = 15\n",
    "data['delay'] = np.where(data['min_diff'] > threshold_in_minutes, 1, 0)\n",
    "\n",
    "training_data = shuffle(data[['OPERA', 'MES', 'TIPOVUELO', 'SIGLADES', 'DIANOM', 'delay']], random_state = 111)\n",
    "\n",
    "features = pd.concat([\n",
    "    pd.get_dummies(data['OPERA'], prefix = 'OPERA'),\n",
    "    pd.get_dummies(data['TIPOVUELO'], prefix = 'TIPOVUELO'), \n",
    "    pd.get_dummies(data['MES'], prefix = 'MES')], \n",
    "    axis = 1\n",
    ")\n",
    "target = data['delay']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.33, random_state = 42)\n",
    "\n",
    "top_10_features = [\n",
    "    \"OPERA_Latin American Wings\", \n",
    "    \"MES_7\",\n",
    "    \"MES_10\",\n",
    "    \"OPERA_Grupo LATAM\",\n",
    "    \"MES_12\",\n",
    "    \"TIPOVUELO_I\",\n",
    "    \"MES_4\",\n",
    "    \"MES_11\",\n",
    "    \"OPERA_Sky Airline\",\n",
    "    \"OPERA_Copa Air\"\n",
    "]\n",
    "\n",
    "n_y0 = len(y_train[y_train == 0])\n",
    "n_y1 = len(y_train[y_train == 1])\n",
    "scale = n_y0/n_y1\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(features[top_10_features], target, test_size = 0.33, random_state = 42)\n",
    "\n",
    "reg_model_2 = LogisticRegression(class_weight={1: n_y0/len(y_train), 0: n_y1/len(y_train)})\n",
    "reg_model_2.fit(x_train2, y_train2)\n",
    "\n",
    "reg_y_preds_2 = reg_model_2.predict(x_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La predicción para el nuevo registro es: Retrasado\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear un nuevo registro como DataFrame\n",
    "new_data = pd.DataFrame({\n",
    "    'OPERA': ['Grupo LATAM'],\n",
    "    'MES': [7],\n",
    "    'TIPOVUELO': ['I'],\n",
    "    'SIGLADES': ['SCL'],\n",
    "    'DIANOM': ['Lunes']\n",
    "})\n",
    "\n",
    "# Generar las variables dummies para el nuevo registro, asegurándonos de incluir solo las columnas necesarias\n",
    "new_data_transformed = pd.concat([\n",
    "    pd.get_dummies(new_data['OPERA'], prefix='OPERA'),\n",
    "    pd.get_dummies(new_data['MES'], prefix='MES'),\n",
    "    pd.get_dummies(new_data['TIPOVUELO'], prefix='TIPOVUELO')\n",
    "], axis=1)\n",
    "\n",
    "# Asegúrarnos de que el DataFrame transformado tenga las mismas columnas que el DataFrame de entrenamiento,\n",
    "# incluso si algunos valores son 0\n",
    "for column in x_train2.columns:\n",
    "    if column not in new_data_transformed.columns:\n",
    "        new_data_transformed[column] = 0\n",
    "\n",
    "new_data_transformed = new_data_transformed[x_train2.columns]\n",
    "\n",
    "# Predicción con el modelo\n",
    "new_prediction = reg_model_2.predict(new_data_transformed)\n",
    "\n",
    "# Output\n",
    "print(\"La predicción para el nuevo registro es:\", \"Retrasado\" if new_prediction[0] == 1 else \"A tiempo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como ../challenge/reg_model_2.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Guardar el modelo en un archivo\n",
    "model_filename = '../challenge/reg_model_2.joblib'\n",
    "dump(reg_model_2, model_filename)\n",
    "\n",
    "print(f'Modelo guardado como {model_filename}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science Conclusions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the results of the 6 trained models, it can be determined:\n",
    "- There is no noticeable difference in results between XGBoost and LogisticRegression.\n",
    "- Does not decrease the performance of the model by reducing the features to the 10 most important.\n",
    "- Improves the model's performance when balancing classes, since it increases the recall of class \"1\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With this, the model to be productive must be the one that is trained with the top 10 features and class balancing, but which one?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
